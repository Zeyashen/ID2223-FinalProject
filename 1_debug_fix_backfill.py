import pandas as pd
import hopsworks
import openmeteo_requests
import requests_cache
from retry_requests import retry

def get_historical_snow_data():
    print("ğŸ“¡ Connecting to Open-Meteo Archive API...")
    
    cache_session = requests_cache.CachedSession('.cache', expire_after = -1)
    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)
    openmeteo = openmeteo_requests.Client(session = retry_session)

    # è·å–æœ€è¿‘2å¹´çš„æ•°æ®
    params = {
        "latitude": 63.399,
        "longitude": 13.082,
        "start_date": "2005-01-01", # æ‰©å¤§ä¸€ç‚¹èŒƒå›´
        "end_date": "2025-01-01",
        "daily": ["temperature_2m_max", "precipitation_sum", "wind_speed_10m_max", "snowfall_sum"],
        "hourly": ["snow_depth"],
        "timezone": "Europe/Berlin"
    }
    
    url = "https://archive-api.open-meteo.com/v1/archive"
    responses = openmeteo.weather_api(url, params=params)
    response = responses[0]

    # --- 1. å¤„ç† Daily æ•°æ® ---
    daily = response.Daily()
    daily_data = {
        "date_obj": pd.date_range(
            start = pd.to_datetime(daily.Time(), unit = "s", utc = True),
            end = pd.to_datetime(daily.TimeEnd(), unit = "s", utc = True),
            freq = pd.Timedelta(seconds = daily.Interval()),
            inclusive = "left"
        )
    }
    daily_data["temperature_max"] = daily.Variables(0).ValuesAsNumpy()
    daily_data["precipitation"] = daily.Variables(1).ValuesAsNumpy()
    daily_data["wind_gusts"] = daily.Variables(2).ValuesAsNumpy()
    daily_data["snowfall_sum"] = daily.Variables(3).ValuesAsNumpy()
    
    df_daily = pd.DataFrame(data = daily_data)
    # åˆ›å»ºä¸€ä¸ªçº¯å‡€çš„ join key
    df_daily['join_date'] = df_daily['date_obj'].dt.strftime('%Y-%m-%d')
    
    print(f"âœ… Daily data fetched. Rows: {len(df_daily)}")

    # --- 2. å¤„ç† Hourly æ•°æ® ---
    hourly = response.Hourly()
    hourly_data = {
        "date_time": pd.date_range(
            start = pd.to_datetime(hourly.Time(), unit = "s", utc = True),
            end = pd.to_datetime(hourly.TimeEnd(), unit = "s", utc = True),
            freq = pd.Timedelta(seconds = hourly.Interval()),
            inclusive = "left"
        )
    }
    hourly_data["snow_depth"] = hourly.Variables(0).ValuesAsNumpy()
    df_hourly = pd.DataFrame(data = hourly_data)
    
    # èšåˆåˆ°å¤©ï¼šæŠŠå°æ—¶è½¬æˆå¤©å­—ç¬¦ä¸²
    df_hourly['join_date'] = df_hourly['date_time'].dt.strftime('%Y-%m-%d')
    # å–æ¯å¤©æœ€å¤§çš„é›ªæ·±
    df_snow_daily = df_hourly.groupby('join_date')['snow_depth'].max().reset_index()
    
    print(f"âœ… Hourly aggregated. Rows: {len(df_snow_daily)}")

    # --- 3. åˆå¹¶ (ä½¿ç”¨å­—ç¬¦ä¸² keyï¼Œæœ€ç¨³å¦¥) ---
    df = pd.merge(df_daily, df_snow_daily, on='join_date', how='inner')
    print(f"ğŸ”— Merged data. Rows: {len(df)}")

    # --- 4. æ¸…æ´— ---
    df = df.dropna()
    print(f"ğŸ§¹ After dropping NaNs. Rows: {len(df)}")
    
    if len(df) == 0:
        raise ValueError("âŒ Error: Dataframe is empty! Check API parameters or merge logic.")

    # --- 5. æ ¼å¼åŒ–æœ€ç»ˆåˆ— ---
    # æ¢å¤ date ä¸ºæ—¶é—´æˆ³ (Event Time)
    df['date'] = pd.to_datetime(df['join_date'])
    # åˆ›å»º date_str (Primary Key)
    df['date_str'] = df['join_date'].astype("string")
    
    # åˆ é™¤ä¸´æ—¶åˆ—
    df = df.drop(columns=['date_obj', 'join_date'])
    
    # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼Œå¥½çœ‹ä¸€ç‚¹
    cols = ['date', 'date_str', 'temperature_max', 'precipitation', 'wind_gusts', 'snowfall_sum', 'snow_depth']
    df = df[cols]
    
    return df

def run_job():
    # 1. è·å–æ•°æ®
    try:
        df = get_historical_snow_data()
        print(f"ğŸ“Š Final Dataset Preview:\n{df.head()}")
    except Exception as e:
        print(e)
        return

    # 2. ç™»å½• Hopsworks
    print("ğŸ” Logging into Hopsworks...")
    project = hopsworks.login()
    fs = project.get_feature_store()

    # 3. åˆ é™¤æ—§çš„ Version 2 (å¦‚æœæœ‰)
    print("ğŸ§¹ Checking for old empty Feature Group...")
    try:
        old_fg = fs.get_feature_group(name="ski_weather_data", version=2)
        old_fg.delete()
        print("ğŸ—‘ï¸ Deleted old empty Feature Group version 2.")
    except:
        print("â„¹ï¸ No old version 2 found.")

    # 4. åˆ›å»ºå¹¶ä¸Šä¼ 
    print("ğŸš€ Uploading to Feature Store (Version 2)...")
    
    ski_fg = fs.get_or_create_feature_group(
        name="ski_weather_data",
        version=3,
        primary_key=["date_str"], 
        event_time="date",
        description="Daily weather and aggregated snow depth for Are",
        online_enabled=True
    )

    ski_fg.insert(df)
    print("ğŸ‰ Success! Data successfully backfilled.")
    print("â³ Please wait 1-2 minutes for the data to be indexed before running the training script.")

if __name__ == "__main__":
    run_job()